{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npy/mfcc\n",
      "\n",
      "Adding fold_0\n",
      "New Features:  (2216, 44)\n",
      "\n",
      "Adding fold_1\n",
      "New Features:  (1954, 44)\n",
      "\n",
      "Adding fold_2\n",
      "New Features:  (2162, 44)\n",
      "\n",
      "Adding fold_3\n",
      "New Features:  (2120, 44)\n",
      "\n",
      "Adding fold_4\n",
      "New Features:  (2136, 44)\n",
      "\n",
      "Adding fold_5\n",
      "New Features:  (2206, 44)\n",
      "\n",
      "Adding fold_6\n",
      "New Features:  (2155, 44)\n",
      "\n",
      "Training Set: (14949, 44), Labels: (14949, 6)\n",
      "Train-dev Set: (2000, 44), Labels: (2000, 6)\n",
      "Dev Set: (2436, 44), Labels: (2436, 6)\n",
      "Test Set: (2060, 44), Labels: (2060, 6)\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"npy\"\n",
    "\n",
    "mfcc=True\n",
    "if mfcc:\n",
    "    data_dir = os.path.join(data_dir, 'mfcc')\n",
    "else:\n",
    "    data_dir = os.path.join(data_dir, 'all')\n",
    "print(data_dir)\n",
    "\n",
    "def add_folds(data_dir, mfcc=False):\n",
    "    num_folds = len(os.listdir(data_dir)) // 2\n",
    "        \n",
    "    for k in range(num_folds-3):\n",
    "        fold_name = 'fold_' + str(k)\n",
    "        print(\"\\nAdding \" + fold_name)\n",
    "        if mfcc:\n",
    "            fold_name += '_mfcc'\n",
    "        feature_file = os.path.join(data_dir, fold_name + '_x.npy')\n",
    "        labels_file = os.path.join(data_dir, fold_name + '_y.npy')\n",
    "        loaded_features = np.load(feature_file)\n",
    "        loaded_labels = np.load(labels_file)\n",
    "        print(\"New Features: \", loaded_features.shape)\n",
    "\n",
    "        if k > 0:\n",
    "            features = np.concatenate((features, loaded_features))\n",
    "            labels = np.concatenate((labels, loaded_labels))\n",
    "        else:\n",
    "            features = loaded_features\n",
    "            labels = loaded_labels\n",
    "    return features, labels\n",
    "\n",
    "train_x, train_y = add_folds(data_dir, mfcc=mfcc)\n",
    "\n",
    "# use a fold for train-dev\n",
    "valid_fold_name = 'fold_7'\n",
    "if mfcc:\n",
    "    valid_fold_name += '_mfcc'\n",
    "feature_file = os.path.join(data_dir, valid_fold_name + '_x.npy')\n",
    "labels_file = os.path.join(data_dir, valid_fold_name + '_y.npy')\n",
    "train_dev_x = np.load(feature_file)\n",
    "train_dev_y = np.load(labels_file) \n",
    "\n",
    "# use a fold for dev\n",
    "valid_fold_name = 'fold_8'\n",
    "if mfcc:\n",
    "    valid_fold_name += '_mfcc'\n",
    "feature_file = os.path.join(data_dir, valid_fold_name + '_x.npy')\n",
    "labels_file = os.path.join(data_dir, valid_fold_name + '_y.npy')\n",
    "dev_x = np.load(feature_file)\n",
    "dev_y = np.load(labels_file) \n",
    "\n",
    "# and a fold for testing\n",
    "test_fold_name = 'fold_9'\n",
    "if mfcc:\n",
    "    test_fold_name += '_mfcc'\n",
    "feature_file = os.path.join(data_dir, test_fold_name + '_x.npy')\n",
    "labels_file = os.path.join(data_dir, test_fold_name + '_y.npy')\n",
    "test_x = np.load(feature_file)\n",
    "test_y = np.load(labels_file)\n",
    "\n",
    "# # One hot encode labels\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "ohe.fit(train_y.reshape(-1, 1))\n",
    "\n",
    "train_y = ohe.transform(train_y.reshape((-1, 1)))\n",
    "num_labels = len(train_y[1])\n",
    "train_dev_y = ohe.transform(train_dev_y.reshape((-1, 1)))\n",
    "dev_y = ohe.transform(dev_y.reshape((-1, 1)))\n",
    "test_y = ohe.transform(test_y.reshape((-1, 1)))\n",
    "\n",
    "print(f\"\\nTraining Set: {train_x.shape}, Labels: {train_y.shape}\")\n",
    "print(f\"Train-dev Set: {train_dev_x.shape}, Labels: {train_dev_y.shape}\")\n",
    "print(f\"Dev Set: {dev_x.shape}, Labels: {dev_y.shape}\")\n",
    "print(f\"Test Set: {test_x.shape}, Labels: {test_y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 5 layer ffn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 44)                1980      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               18000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 1206      \n",
      "=================================================================\n",
      "Total params: 101,386\n",
      "Trainable params: 101,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "def create_model(activation='relu', dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    n = train_x.shape[1]\n",
    "    model.add(Dense(n, input_dim=n, activation=activation))\n",
    "    model.add(Dense(400, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(200, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(num_labels, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=SGD(), metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14949 samples, validate on 2436 samples\n",
      "Epoch 1/5\n",
      "14949/14949 [==============================] - 2s 139us/step - loss: 0.4522 - acc: 0.8333 - val_loss: 0.4532 - val_acc: 0.8333\n",
      "Epoch 2/5\n",
      "14949/14949 [==============================] - 2s 132us/step - loss: 0.4513 - acc: 0.8334 - val_loss: 0.4535 - val_acc: 0.8333\n",
      "Epoch 3/5\n",
      "14949/14949 [==============================] - 2s 136us/step - loss: 0.4506 - acc: 0.8332 - val_loss: 0.4535 - val_acc: 0.8333\n",
      "Epoch 4/5\n",
      "14949/14949 [==============================] - 2s 149us/step - loss: 0.4495 - acc: 0.8333 - val_loss: 0.4563 - val_acc: 0.8333\n",
      "Epoch 00004: early stopping\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "earlystop_acc = EarlyStopping(monitor='val_acc', patience=3, verbose=1, mode='auto')\n",
    "history = model.fit(train_x, train_y, \n",
    "                    validation_data=(dev_x, dev_y), \n",
    "                    callbacks=[earlystop, earlystop_acc], \n",
    "                    epochs=5, \n",
    "                    batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2060/2060 [==============================] - 0s 45us/step\n",
      "\n",
      "Accuracy = 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Accuracy\n",
    "score, accuracy = model.evaluate(test_x, test_y, batch_size=28)\n",
    "print(\"\\nAccuracy = {:.2f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -5.14738010e+02   3.15824851e+01   4.11918949e-01   1.14085354e+01\n",
      "   4.92827374e+00  -4.00655012e+00   2.61576622e+00  -1.53363998e+00\n",
      "  -9.63345583e-01  -3.68915570e+00  -1.45786379e+00   1.06148858e+00\n",
      "  -2.06182512e+00   2.88264994e-01  -2.18621514e-02   1.29873050e+00\n",
      "   6.26811781e-02   3.60362166e-01  -5.79874571e+00   8.62707083e-01\n",
      "  -1.73691011e+00  -1.63855675e+00  -1.98191873e+00   3.67625277e-01\n",
      "  -3.11123766e+00   2.20682403e+00  -1.88472337e+00  -4.98203053e-01\n",
      "  -1.39676903e-01   3.58229408e+00  -1.66338026e-01   5.04445329e+00\n",
      "   2.72010043e+00   4.41178897e+00   1.31283229e+00   1.11532746e+00\n",
      "  -3.82165983e-02   4.65353289e-01   4.52625281e-01   7.75063905e-01\n",
      "  -2.46275152e+00   2.10422973e+00   3.82571361e-01  -1.82751553e-02]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.10391551,  0.16527979,  0.11279739,  0.19691423,  0.29134184,\n",
       "         0.09986485]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += (window_size // 2)\n",
    "\n",
    "def extract_features_mfcc(file_name, bands=60, frames=32, n_mfcc=42):\n",
    "    \"\"\"\n",
    "    Generate multiple windows to be used as examples in the sound file. \n",
    "    \"\"\"\n",
    "    window_size = 512 * (frames - 1)\n",
    "    X, sr = librosa.load(file_name)\n",
    "    features = []\n",
    "\n",
    "    for (start, end) in windows(X, window_size):\n",
    "        if end > len(X):\n",
    "            break\n",
    "        curr_win_size = len(X[start:end])\n",
    "        if(curr_win_size != window_size):\n",
    "            break\n",
    "        signal = X[start:end]\n",
    "        mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc)  # mfcc.shape = (42, 1002) \n",
    "        mfccs = np.mean(mfcc.T,axis=0)  # mean along mfcc columns mfccs.shape = (42, )\n",
    "        mfcc_ds = np.mean(librosa.feature.delta(mfcc.T, axis=0))\n",
    "        mfcc_d_ds = np.mean(librosa.feature.delta(mfcc.T, order=2))\n",
    "        feature_vecs = np.hstack([mfccs, mfcc_ds, mfcc_d_ds])\n",
    "        features.append(feature_vecs)\n",
    "    return features\n",
    "\n",
    "sample_filename = \"data/speech-accent-archive/recordings/afghanistan/dari1.mp3\"\n",
    "features = extract_features_mfcc(sample_filename)\n",
    "f = features[0]\n",
    "print(f)\n",
    "model.predict(np.array([f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229",
   "language": "python",
   "name": "cs229-final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
