{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" usage:\n",
    "        a4.py train TRAIN_FEATURE_FILE [--new] [--validate]\n",
    "        a4.py classify MUSIC_FEATURE_FILE\n",
    "    The files should be CSV with 6 columns, the last of which is the target/label/class (or empty, if classifying), and the first of which is ignored.\n",
    "\"\"\"\n",
    "#-------------------------------------------------------------------------------\n",
    "# Name: Pat Kujawa\n",
    "# Purpose: MM audio classification asn 4\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "from __future__ import division\n",
    "import os, sys\n",
    "import docopt\n",
    "\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "picklePath = r\"classifier.pickle\"\n",
    "target_names = ['speech', 'music']  # false, true\n",
    "\n",
    "\n",
    "def preProcess(csvFile, classifying=False):\n",
    "    \"\"\"Returns (data, targets) where targets is bool array repr IsMusic.\n",
    "    \"\"\"\n",
    "##    csvFile = r\"C:\\Users\\Pat\\Dropbox\\UM Grad School\\2013 Fall\\Multimedia MM processing 578\\asn4-audio-classifier\\energy,zc,zcr,centroid,bw,name,ismusic.csv\"\n",
    "##    datatable = np.genfromtxt(csvFile, delimiter=',', names=True, dtype=None)\n",
    "##    featureTable = datatable[sorted(list(set(datatable.dtype.names) - {'zc', 'ismusic', 'name'}))]  # use zero crossing rate instead of absolute count; ditch non-feature data\n",
    "##    classifications = datatable['ismusic']  # bool\n",
    "\n",
    "    names = np.genfromtxt(csvFile, delimiter=',', usecols=(0), dtype=str)\n",
    "    data = np.genfromtxt(csvFile, delimiter=',', usecols=(1,2,3,4))\n",
    "    if classifying:\n",
    "        targets = None\n",
    "    else:\n",
    "        targets = np.genfromtxt(csvFile, delimiter=',', usecols=(5), dtype=bool)  # bool ismusic\n",
    "    return data, names, targets\n",
    "\n",
    "\n",
    "def train(data, names, targets, startNew=False, cv=False):\n",
    "    \"\"\"Create and serialize a classifier trained on 2/3 of the input data.\n",
    "        :param startNew: create a new classifier if true else add to the training of the previous classifier\n",
    "        :param cv: do cross-validation with a subset of items\n",
    "    \"\"\"\n",
    "    classifier = None\n",
    "    if not startNew:\n",
    "        try:\n",
    "            with open(picklePath, 'rb') as f:\n",
    "                classifier = pickle.load(f)\n",
    "        except:\n",
    "            sys.stderr.write(\"Couldn't deserialize classifier. Creating a new one instead \\n\")\n",
    "\n",
    "    t = targets\n",
    "\n",
    "    # From DZone.com refcard: Data Mining - Discovering and Visualizing Patterns with Python by Giuseppe Vettigli\n",
    "    classifier = classifier or GaussianNB()\n",
    "    if not cv:\n",
    "        classifier.fit(data, t) # training\n",
    "        print 'Trained on all files:', ','.join(names)\n",
    "        return ''\n",
    "\n",
    "    ##from sklearn import svm\n",
    "    ##classifier = svm.SVC()  # classifying all as Speech\n",
    "\n",
    "    # t_ means target, as in expected/desired classification\n",
    "    train, test, t_train, t_test, trainFiles, testFiles = \\\n",
    "            cross_validation.train_test_split(data, t, names, test_size=0.33)\n",
    "\n",
    "    # show which files are used for train/test\n",
    "    print 'Training files:', ','.join(trainFiles)\n",
    "##    print sum((s.startswith(\"mu\") for s in trainFiles)), 'music files /', len(trainFiles)\n",
    "    print 'Test files:', ','.join(testFiles)\n",
    "\n",
    "    classifier.fit(train, t_train)  # train\n",
    "\n",
    "    print 'Prior probabilities (n={}):'.format(len(trainFiles))\n",
    "    for cls, prob in zip(classifier.classes_, classifier.class_prior_):\n",
    "        print target_names[cls], prob\n",
    "\n",
    "    print \"Accuracy for 2/3 training, 1/3 test:\"\n",
    "    print classifier.score(test, t_test)  # test\n",
    "    # 0.0625 :(\n",
    "\n",
    "    print \"Confusion matrix for 2/3 training, 1/3 test:\"\n",
    "    print confusion_matrix(classifier.predict(test), t_test)\n",
    "    ##[[2 2]\n",
    "    ## [4 8]]\n",
    "\n",
    "    print 'Classification report for 2/3 training, 1/3 test:'\n",
    "    print classification_report(classifier.predict(test),\n",
    "            t_test, target_names=target_names)\n",
    "\n",
    "    print 'leave one out cv'\n",
    "    # cross validation with leave one out\n",
    "    # http://stackoverflow.com/questions/17499068/train-scikit-svm-customize-score-assessment\n",
    "    scores = cross_val_score(classifier, data, t,\n",
    "            cv=cross_validation.LeaveOneOut(len(t)))\n",
    "    print scores, np.sum(scores), '/', len(scores), '=', np.mean(scores)\n",
    "\n",
    "    try:\n",
    "        with open(picklePath, 'wb') as f:\n",
    "            pickle.dump(classifier, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except:\n",
    "        sys.stderr.write(\"Error persisting classifier to file. Are you in a protected directory\\n\")\n",
    "    globals().update(locals())\n",
    "    return ''\n",
    "\n",
    "\n",
    "def classify(data):\n",
    "    \"\"\"Predict the class of the data from a deserialized classifier.\n",
    "    \"\"\"\n",
    "    assert data.ndim == 1\n",
    "    try:\n",
    "        with open(picklePath, 'rb') as f:\n",
    "            classifier = pickle.load(f)\n",
    "    except:\n",
    "        sys.stderr.write(\"Error: no classifier found. Need to train first.\\n\")\n",
    "        return\n",
    "    result = classifier.predict(data)\n",
    "    globals().update(locals())\n",
    "    return target_names[result[0]]\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = docopt.docopt(__doc__, options_first=False)\n",
    "    if args['train']:\n",
    "        print(\"train(*preProcess(args['TRAIN_FEATURE_FILE']),startNew=args['--new'], cv=args['--validate'])\")\n",
    "    elif args['classify']:\n",
    "        print(\"classify(preProcess(args['MUSIC_FEATURE_FILE'])[0])\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229",
   "language": "python",
   "name": "cs229-final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
