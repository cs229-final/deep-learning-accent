{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features\n",
    "\n",
    "### Single file example extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/leonmak/Documents/CS229/final-project/data/SC-scripted-word/CH/SC_W_CH_04_EN-chunk-5.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c0e694321978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# sample_filename = 'data/speech-accent-archive/recordings/afghanistan/dari2.mp3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0msample_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/leonmak/Documents/CS229/final-project/data/SC-scripted-word/CH/SC_W_CH_04_EN-chunk-5.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_feature_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mdata_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'IN: Initial Data Points ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c0e694321978>\u001b[0m in \u001b[0;36mextract_feature_array\u001b[0;34m(filename, bands, frames)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmfccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msound_clip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m44100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msound_clip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrawread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrawread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRawAudioFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \"\"\"\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/leonmak/Documents/CS229/final-project/data/SC-scripted-word/CH/SC_W_CH_04_EN-chunk-5.wav'"
     ]
    }
   ],
   "source": [
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += (window_size // 2)\n",
    "\n",
    "def extract_feature_array(filename, bands=21, frames=41):\n",
    "    window_size = 512 * (frames-1)\n",
    "    mfccs = []\n",
    "    sound_clip, s = librosa.load(filename, sr=44100)\n",
    "    for (start, end) in windows(sound_clip, window_size):\n",
    "        start = int(start)\n",
    "        end = int(end)\n",
    "        if(len(sound_clip[start:end]) == window_size):\n",
    "            signal = sound_clip[start:end]\n",
    "            mfcc = librosa.feature.mfcc(signal, sr=s, n_mfcc=bands)\n",
    "            mfccs.append(mfcc)\n",
    "#             mfcc = librosa.feature.mfcc(signal, sr=s, n_mfcc=bands).T.flatten()[:, np.newaxis].T\n",
    "#             logspec = librosa.logamplitude(melspec)\n",
    "#     log_specgrams = np.expand_dims(np.asarray(log_specgrams), axis=3)\n",
    "    return np.asarray(mfccs)\n",
    "\n",
    "# # Uncomment if using deltas\n",
    "#\n",
    "#     log_specgrams = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
    "#     features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis = 3)\n",
    "#     for i in range(len(features)):\n",
    "#         features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "#     return np.array(features)\n",
    "\n",
    "# sample_filename = 'data/speech-accent-archive/recordings/afghanistan/dari2.mp3'\n",
    "sample_filename = '/Users/leonmak/Documents/CS229/final-project/data/SC-scripted-word/CH/SC_W_CH_04_EN-chunk-5.wav'\n",
    "features = extract_feature_array(sample_filename)\n",
    "data_points, _ = librosa.load(sample_filename)\n",
    "print ('IN: Initial Data Points =', len(data_points))\n",
    "print ('OUT: Total features =', np.shape(features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 labels found, First 5: ['CH', 'EN', 'IN', 'IR', 'IT']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def iter_label_files(parent_dir):\n",
    "    \"\"\"Utility for extracting labels\"\"\"\n",
    "    for root, dirpaths, fnames in os.walk(parent_dir):\n",
    "        if len(dirpaths) > 0:\n",
    "            continue\n",
    "        label = root.split('/')[-1]\n",
    "        yield root, label, fnames\n",
    "\n",
    "# parent_dir = 'data/speech-accent-archive/recordings/'\n",
    "parent_dir = 'data/SC-scripted-word/'\n",
    "labels = []\n",
    "for _, label, _ in iter_label_files(parent_dir):\n",
    "    labels.append(label)\n",
    "print(f'{len(labels)} labels found, First 5: {labels[:5]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels with >= 2134 egs: ['KO', 'EN', 'CH'], len:3\n",
      "[[ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "cap = 2134\n",
    "counts = []\n",
    "for _, label, fnames in iter_label_files(parent_dir):\n",
    "    counts.append(len(fnames))\n",
    "\n",
    "top_indices_count = [i_count for i_count in sorted(enumerate(counts), key=lambda x:x[1], reverse=True)]\n",
    "most_freq_egs = [labels[i] for (i, count) in top_indices_count if count >= cap]\n",
    "print(f'Labels with >= {cap} egs: {most_freq_egs}, len:{len(most_freq_egs)}')    \n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "le_ed = le.fit_transform(most_freq_egs)\n",
    "ohe_ed = ohe.fit_transform(le_ed.reshape(len(le_ed), 1))\n",
    "print(ohe_ed.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving feature_file npy/mfcc_w/fold_orig_w0_x.npy \n",
      "Saving labels_file npy/mfcc_w/fold_orig_w0_y.npy\n",
      "Features of fold_orig_w0 = (639, 50, 44)\n",
      "Labels of fold_orig_w0 = (639,)\n",
      "Saving feature_file npy/mfcc_w/fold_orig_w1_x.npy \n",
      "Saving labels_file npy/mfcc_w/fold_orig_w1_y.npy\n",
      "Features of fold_orig_w1 = (639, 50, 44)\n",
      "Labels of fold_orig_w1 = (639,)\n",
      "Saving feature_file npy/mfcc_w/fold_orig_w2_x.npy \n",
      "Saving labels_file npy/mfcc_w/fold_orig_w2_y.npy\n",
      "Features of fold_orig_w2 = (639, 50, 44)\n",
      "Labels of fold_orig_w2 = (639,)\n",
      "Saving feature_file npy/mfcc_w/fold_orig_w3_x.npy \n",
      "Saving labels_file npy/mfcc_w/fold_orig_w3_y.npy\n",
      "Features of fold_orig_w3 = (639, 50, 44)\n",
      "Labels of fold_orig_w3 = (639,)\n",
      "Saving feature_file npy/mfcc_w/fold_orig_w4_x.npy \n",
      "Saving labels_file npy/mfcc_w/fold_orig_w4_y.npy\n",
      "Features of fold_orig_w4 = (639, 50, 44)\n",
      "Labels of fold_orig_w4 = (639,)\n",
      "Saving feature_file npy/mfcc_w/fold_orig_w5_x.npy \n",
      "Saving labels_file npy/mfcc_w/fold_orig_w5_y.npy\n",
      "Features of fold_orig_w5 = (639, 50, 44)\n",
      "Labels of fold_orig_w5 = (639,)\n",
      "Saving feature_file npy/mfcc_w/fold_orig_w6_x.npy \n",
      "Saving labels_file npy/mfcc_w/fold_orig_w6_y.npy\n",
      "Features of fold_orig_w6 = (639, 50, 44)\n",
      "Labels of fold_orig_w6 = (639,)\n",
      "Saving feature_file npy/mfcc_w/fold_orig_w7_x.npy \n",
      "Saving labels_file npy/mfcc_w/fold_orig_w7_y.npy\n",
      "Features of fold_orig_w7 = (639, 50, 44)\n",
      "Labels of fold_orig_w7 = (639,)\n",
      "Saving feature_file npy/mfcc_w/fold_orig_w8_x.npy \n",
      "Saving labels_file npy/mfcc_w/fold_orig_w8_y.npy\n",
      "Features of fold_orig_w8 = (639, 50, 44)\n",
      "Labels of fold_orig_w8 = (639,)\n",
      "Saving feature_file npy/mfcc_w/fold_orig_w9_x.npy \n",
      "Saving labels_file npy/mfcc_w/fold_orig_w9_y.npy\n",
      "Features of fold_orig_w9 = (639, 50, 44)\n",
      "Labels of fold_orig_w9 = (639,)\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import speechpy\n",
    "\n",
    "NUM_MFCCS = 50\n",
    "DEFAULT_BITRATE = 22050\n",
    "DESIRED_DURATION = 1  # seconds\n",
    "PADDED_LENGTH = DEFAULT_BITRATE * DESIRED_DURATION\n",
    "\n",
    "\n",
    "def get_label_enc(fn, le):\n",
    "    fn_parts = fn.split('/')\n",
    "    label_txt = fn_parts[-2]  # y_i\n",
    "    label_int = le.transform([label_txt])\n",
    "    return label_int[0]\n",
    "\n",
    "\n",
    "def normalize_audio(source_files):\n",
    "    fixed_lengths = [librosa.util.fix_length(y, PADDED_LENGTH) for y, _ in source_files]\n",
    "    return [(f - np.mean(f)) / np.std(f) for f in fixed_lengths]\n",
    "\n",
    "\n",
    "def load_audio(source_files):\n",
    "    loaded_mp3_files = [librosa.load(f) for f in source_files]\n",
    "    fix_length_mp3 = normalize_audio(loaded_mp3_files)\n",
    "    mfccs = [librosa.feature.mfcc(y=y, sr=DEFAULT_BITRATE, n_mfcc=NUM_MFCCS) for y in fix_length_mp3]\n",
    "    return mfccs\n",
    "\n",
    "\n",
    "def get_labels(fnames):\n",
    "    labels = [get_label_enc(fn, le) for fn in fnames]\n",
    "    return labels\n",
    "\n",
    "\n",
    "def extract_feature(fnames):\n",
    "    \"\"\"\n",
    "    Extract features from filenames to features and labels arrays\n",
    "    \"\"\"\n",
    "    mfccs = load_audio(fnames)\n",
    "    labels = get_labels(fnames)\n",
    "    return np.asarray(mfccs), np.asarray(labels)\n",
    "#     window_size = 512 * (frames-1)\n",
    "#     log_specgrams = []\n",
    "#     mfccs = []\n",
    "#     labels = []\n",
    "#     for fn in fnames:\n",
    "#         sound_clip, s = librosa.load(fn)\n",
    "# #         sound_clip -= np.mean(sound_clip)\n",
    "# #         sound_clip /= max(sound_clip)\n",
    "#         label_enc = get_label_enc(fn, le)\n",
    "#         for (start, end) in windows(sound_clip, window_size):\n",
    "#             signal = sound_clip[start:end]\n",
    "#             if(len(signal) != window_size):\n",
    "#                 break\n",
    "#             labels.append(label_enc)\n",
    "# #             melspec = librosa.feature.mfcc(signal, sr=s, n_mels=bands)\n",
    "# #             logspec = librosa.logamplitude(melspec)\n",
    "# #             log_specgrams.append(logspec)\n",
    "#             mfcc = librosa.feature.mfcc(signal, sr=s, n_mfcc=bands)\n",
    "#             mfccs.append(mfcc)\n",
    "#     if word == False:\n",
    "#         log_specgrams = np.expand_dims(np.asarray(log_specgrams), axis=3)\n",
    "#     return np.asarray(mfccs), np.asarray(labels, dtype='int')\n",
    "#     log_specgrams = np.array(log_specgrams).reshape(len(log_specgrams),bands,frames,2)\n",
    "#     features = np.concatenate((log_specgrams, np.zeros(log_specgrams.shape)), axis=3)\n",
    "#     for i in range(len(features)):\n",
    "#         features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "#     return np.array(features), np.array(labels, dtype='int')\n",
    "\n",
    "\n",
    "def get_subset_fnames():\n",
    "    subset_fnames = []\n",
    "    for root, label, fnames in iter_label_files(parent_dir):\n",
    "        if label not in most_freq_egs:\n",
    "            continue\n",
    "        for fn in fnames[:cap]:\n",
    "            if '.DS_Store' in fn:\n",
    "                continue\n",
    "            subset_fnames.append(os.path.join(root, fn))\n",
    "    random.seed(24)\n",
    "    random.shuffle(subset_fnames)\n",
    "    return subset_fnames\n",
    "\n",
    "\n",
    "def save_folds(save_dir, num_folds=10, fold_prefix='fold_orig_w'):\n",
    "    fnames = get_subset_fnames()\n",
    "    egs_per_fold = len(fnames) // num_folds\n",
    "    curr = 0\n",
    "    features = []\n",
    "    labels = []\n",
    "    for k in range(num_folds):\n",
    "        fold_name = f'{fold_prefix}{str(k)}'\n",
    "        \n",
    "        feature_file = os.path.join(save_dir, fold_name + '_x.npy')\n",
    "        labels_file = os.path.join(save_dir, fold_name + '_y.npy')\n",
    "\n",
    "        print(f'Saving feature_file {feature_file} \\nSaving labels_file {labels_file}')\n",
    "        start_i = k * egs_per_fold\n",
    "        end_i = (k + 1) * egs_per_fold\n",
    "        fnames_fold = fnames[start_i: end_i]\n",
    "        features, labels = extract_feature(fnames_fold)\n",
    "#         features = np.concatenate([features, new_features]) if len(features) > 0 else np.asarray(new_features)\n",
    "#         labels = np.concatenate([labels, new_labels]) if len(labels) > 0 else np.asarray(new_labels)\n",
    "        print(f'Features of {fold_name} = {features.shape}')\n",
    "        print(f'Labels of {fold_name} = {labels.shape}')\n",
    "\n",
    "        np.save(feature_file, features)\n",
    "        np.save(labels_file, labels)\n",
    "\n",
    "\n",
    "save_dir=os.path.join('npy', 'mfcc_w')\n",
    "save_folds(save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npy/mfcc_w\n",
      "\n",
      "Adding fold_orig_w0\n",
      "New Features:  (1278, 50, 44) (1278,)\n",
      "\n",
      "Adding fold_orig_w1\n",
      "New Features:  (1278, 50, 44) (1278,)\n",
      "\n",
      "Adding fold_orig_w2\n",
      "New Features:  (1278, 50, 44) (1278,)\n",
      "\n",
      "Adding fold_orig_w3\n",
      "New Features:  (1278, 50, 44) (1278,)\n",
      "\n",
      "Adding fold_orig_w4\n",
      "New Features:  (1278, 50, 44) (1278,)\n",
      "\n",
      "Adding fold_orig_w5\n",
      "New Features:  (1278, 50, 44) (1278,)\n",
      "\n",
      "Adding fold_orig_w6\n",
      "New Features:  (1278, 50, 44) (1278,)\n",
      "\n",
      "Training Set: (8946, 50, 44), Labels: (8946, 3)\n",
      "Train-dev Set: (639, 50, 44), Labels: (639, 3)\n",
      "Dev Set: (639, 50, 44), Labels: (639, 3)\n",
      "Test Set: (639, 50, 44), Labels: (639, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "data_dir = os.path.join('npy', 'mfcc_w')\n",
    "print(data_dir)\n",
    "fold_prefix = 'fold_orig_w'\n",
    "\n",
    "def add_folds(data_dir):\n",
    "    files_lst = os.listdir(data_dir)\n",
    "    num_folds = len(list(filter(lambda k: fold_prefix in k, files_lst))) // 2\n",
    "        \n",
    "    for k in range(num_folds-3):\n",
    "        fold_name = f'{fold_prefix}{str(k)}'\n",
    "        print(\"\\nAdding \" + fold_name)\n",
    "        feature_file = os.path.join(data_dir, fold_name + '_x.npy')\n",
    "        labels_file = os.path.join(data_dir, fold_name + '_y.npy')\n",
    "\n",
    "        loaded_features = np.load(feature_file)\n",
    "        loaded_labels = np.load(labels_file)\n",
    "        \n",
    "        # Data Augmentation with Gaussian Noise\n",
    "        noise = np.random.normal(0,1, loaded_features.shape)\n",
    "        loaded_features = np.concatenate([loaded_features, loaded_features+noise])\n",
    "        loaded_labels = np.concatenate([loaded_labels, loaded_labels])\n",
    "        \n",
    "        print(\"New Features: \", loaded_features.shape, loaded_labels.shape)\n",
    "        if k > 0:\n",
    "            features = np.concatenate((features, loaded_features))\n",
    "            labels = np.concatenate((labels, loaded_labels))\n",
    "        else:\n",
    "            features = loaded_features\n",
    "            labels = loaded_labels\n",
    "    return features, labels\n",
    "\n",
    "train_x, train_y = add_folds(data_dir)\n",
    "\n",
    "# use a fold for train-dev\n",
    "valid_fold_name = f'{fold_prefix}7'\n",
    "feature_file = os.path.join(data_dir, valid_fold_name + '_x.npy')\n",
    "labels_file = os.path.join(data_dir, valid_fold_name + '_y.npy')\n",
    "train_dev_x = np.load(feature_file)\n",
    "train_dev_y = np.load(labels_file) \n",
    "\n",
    "# use a fold for dev\n",
    "valid_fold_name = f'{fold_prefix}8'\n",
    "feature_file = os.path.join(data_dir, valid_fold_name + '_x.npy')\n",
    "labels_file = os.path.join(data_dir, valid_fold_name + '_y.npy')\n",
    "dev_x = np.load(feature_file)\n",
    "dev_y = np.load(labels_file) \n",
    "\n",
    "# and a fold for testing\n",
    "test_fold_name = f'{fold_prefix}9'\n",
    "feature_file = os.path.join(data_dir, test_fold_name + '_x.npy')\n",
    "labels_file = os.path.join(data_dir, test_fold_name + '_y.npy')\n",
    "test_x = np.load(feature_file)\n",
    "test_y = np.load(labels_file)\n",
    "\n",
    "\n",
    "# encode\n",
    "train_y = to_categorical(train_y)\n",
    "train_dev_y = to_categorical(train_dev_y)\n",
    "dev_y = to_categorical(dev_y)\n",
    "test_y = to_categorical(test_y)\n",
    "\n",
    "# train_x = np.expand_dims(np.asarray(train_x), axis=3)\n",
    "# train_dev_x = np.expand_dims(np.asarray(train_dev_x), axis=3)\n",
    "# dev_x = np.expand_dims(np.asarray(dev_x), axis=3)\n",
    "# test_x = np.expand_dims(np.asarray(test_x), axis=3)\n",
    "\n",
    "# trim data\n",
    "# last = min([len(train_x), len(train_dev_x), len(dev_x), len(test_x)])\n",
    "# train_dev_x, train_dev_y = train_dev_x, train_dev_y\n",
    "# dev_x, dev_y = dev_x[:last], dev_y[:last]\n",
    "# test_x, test_y = test_x[:last], test_y[:last]\n",
    "\n",
    "print(f\"\\nTraining Set: {train_x.shape}, Labels: {train_y.shape}\")\n",
    "print(f\"Train-dev Set: {train_dev_x.shape}, Labels: {train_dev_y.shape}\")\n",
    "print(f\"Dev Set: {dev_x.shape}, Labels: {dev_y.shape}\")\n",
    "print(f\"Test Set: {test_x.shape}, Labels: {test_y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 48, 128)           17024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 48, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 22, 64)            24640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 22, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 11, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 9, 24)             4632      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 9, 24)             96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 4, 24)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 124)               12028     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 375       \n",
      "=================================================================\n",
      "Total params: 59,563\n",
      "Trainable params: 59,131\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, Conv2D, MaxPool1D, MaxPool2D, MaxPooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import categorical_accuracy\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "from librosa.util import fix_length\n",
    "\n",
    "bands = 50\n",
    "frames = 1077\n",
    "feature_size = bands * frames\n",
    "num_labels = len(most_freq_egs)\n",
    "input_shape = (bands, frames)\n",
    "# input_shape=(bands, frames, num_channels) # if have delta num_channels = 1\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    f_size = 3\n",
    "    model.add(Conv1D(128, f_size, activation='relu', input_shape=(50, 44)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64, f_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(24, f_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(124, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_labels, activation='softmax', kernel_regularizer=l2(0.001)))\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "    return model\n",
    "print(\"Building model...\")\n",
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 9585 samples, validate on 639 samples\n",
      "Epoch 1/30\n",
      "9585/9585 [==============================] - 11s 1ms/step - loss: 0.5453 - acc: 0.8191 - val_loss: 0.3698 - val_acc: 0.8951\n",
      "Epoch 2/30\n",
      "9585/9585 [==============================] - 10s 996us/step - loss: 0.2120 - acc: 0.9567 - val_loss: 0.3632 - val_acc: 0.9077\n",
      "Epoch 3/30\n",
      "9585/9585 [==============================] - 10s 1ms/step - loss: 0.1215 - acc: 0.9839 - val_loss: 0.2830 - val_acc: 0.9264\n",
      "Epoch 4/30\n",
      "9585/9585 [==============================] - 9s 986us/step - loss: 0.1049 - acc: 0.9858 - val_loss: 0.2659 - val_acc: 0.9374\n",
      "Epoch 5/30\n",
      "9585/9585 [==============================] - 10s 1ms/step - loss: 0.0834 - acc: 0.9884 - val_loss: 0.2851 - val_acc: 0.9374\n",
      "Epoch 6/30\n",
      "9585/9585 [==============================] - 10s 1ms/step - loss: 0.0727 - acc: 0.9902 - val_loss: 0.2378 - val_acc: 0.9452\n",
      "Epoch 7/30\n",
      "9585/9585 [==============================] - 9s 973us/step - loss: 0.0479 - acc: 0.9965 - val_loss: 0.2666 - val_acc: 0.9484\n",
      "Epoch 8/30\n",
      "9585/9585 [==============================] - 9s 930us/step - loss: 0.0413 - acc: 0.9971 - val_loss: 0.2477 - val_acc: 0.9405\n",
      "Epoch 9/30\n",
      "9585/9585 [==============================] - 9s 940us/step - loss: 0.0414 - acc: 0.9956 - val_loss: 0.2281 - val_acc: 0.9531\n",
      "Epoch 10/30\n",
      "9585/9585 [==============================] - 9s 965us/step - loss: 0.0519 - acc: 0.9903 - val_loss: 0.2022 - val_acc: 0.9546\n",
      "Epoch 11/30\n",
      "9585/9585 [==============================] - 9s 979us/step - loss: 0.0319 - acc: 0.9972 - val_loss: 0.2179 - val_acc: 0.9421\n",
      "Epoch 12/30\n",
      "9585/9585 [==============================] - 9s 929us/step - loss: 0.0340 - acc: 0.9955 - val_loss: 0.2306 - val_acc: 0.9421\n",
      "Epoch 13/30\n",
      "9585/9585 [==============================] - 9s 957us/step - loss: 0.0309 - acc: 0.9963 - val_loss: 0.2771 - val_acc: 0.9327\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "history = model.fit(np.concatenate([train_x, train_dev_x]), \n",
    "                    np.concatenate([train_y, train_dev_y]), \n",
    "                    validation_data=(dev_x, dev_y), \n",
    "                    callbacks=[earlystop], \n",
    "                    epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "num_splits=3\n",
    "cnn_estimator = KerasClassifier(build_fn=build_model, epochs=15, batch_size=50, verbose=1)\n",
    "kfold = KFold(n_splits=num_splits, shuffle=True, random_state=1)\n",
    "results = cross_val_score(cnn_estimator, train_x, train_y, cv=kfold)\n",
    "print(\"{num_splits}-fold xval accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "[[  1.00000000e+00   1.43649773e-10   1.44615819e-10]\n",
      " [  1.17868251e-06   9.99987841e-01   1.09654211e-05]\n",
      " [  1.00000000e+00   8.87438922e-09   2.90474311e-08]\n",
      " ..., \n",
      " [  3.03644955e-01   2.94879283e-05   6.96325541e-01]\n",
      " [  9.99455631e-01   3.44818225e-04   1.99578993e-04]\n",
      " [  7.98587294e-08   1.10972258e-04   9.99888897e-01]]\n",
      "pred: [0 1 0 0 0 2 0 0 1 0 0 2 0 0 0 1 1 2 0 1 2 1 0 2 0 1 2 1 1 2 1 1 0 1 0 0 1\n",
      " 0 1 2 1 0 1 0 2 2 0 2 0 2 2 0 0 1 2 0 2 2 1 1 0 1 2 0 1 2 1 1 0 2 2 0 2 2\n",
      " 2 0 0 2 0 2 1 2 2 2 0 2 2 0 1 2 2 0 0 1 0 1 0 1 1 0]\n",
      "test: [0 1 0 0 0 2 0 0 1 0 0 2 0 0 0 1 1 2 0 1 0 1 0 2 0 1 2 1 1 2 1 1 0 1 0 0 1\n",
      " 0 1 2 1 0 1 0 2 2 0 2 0 2 2 0 0 1 2 0 2 2 1 1 0 1 2 0 1 2 1 1 0 2 2 0 2 2\n",
      " 2 0 0 2 0 2 1 2 2 2 0 2 2 0 1 2 2 0 0 1 0 1 0 1 1 0]\n",
      "639/639 [==============================] - 0s 544us/step\n",
      "Accuracy = 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate(model):\n",
    "    y_prob = model.predict_proba(test_x, verbose=0)\n",
    "    print(y_prob)\n",
    "    y_pred = model.predict(test_x)\n",
    "    print(f'pred: {np.argmax(y_pred[:100],axis=1)}')\n",
    "    y_true = np.argmax(test_y)\n",
    "    print(f'test: {np.argmax(test_y[:100],axis=1)}')\n",
    "\n",
    "    # evaluate the model\n",
    "    score, accuracy = model.evaluate(test_x, test_y)\n",
    "    print(\"Accuracy = {:.2f}\".format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# now evaluate the trained model against the unseen test data\n",
    "print(\"Evaluating model...\")\n",
    "acc = evaluate(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, label='Training acc')\n",
    "plt.plot(epochs, val_acc, label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 48, 128)           17024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 48, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 22, 64)            24640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 22, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 11, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 9, 24)             4632      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 9, 24)             96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 4, 24)             0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 124)               12028     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 375       \n",
      "=================================================================\n",
      "Total params: 59,563\n",
      "Trainable params: 59,131\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def rnn_model():        \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, input_shape=(50, 1077), \n",
    "                   recurrent_dropout=0.3, return_sequences=True, kernel_regularizer=l2(0.001)))\n",
    "    model.add(LSTM(32, recurrent_dropout=0.3, return_sequences=True, kernel_regularizer=l2(0.001)))\n",
    "    model.add(LSTM(24, recurrent_dropout=0.3, kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_labels, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(lr=0.0000001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 9585 samples, validate on 639 samples\n",
      "Epoch 1/16\n",
      "9585/9585 [==============================] - 10s 1ms/step - loss: 0.0329 - acc: 0.9931 - val_loss: 0.1833 - val_acc: 0.9609\n",
      "Epoch 2/16\n",
      "9585/9585 [==============================] - 12s 1ms/step - loss: 0.0236 - acc: 0.9958 - val_loss: 0.2233 - val_acc: 0.9577\n",
      "Epoch 3/16\n",
      "9585/9585 [==============================] - 9s 968us/step - loss: 0.0200 - acc: 0.9970 - val_loss: 0.1739 - val_acc: 0.9609\n",
      "Epoch 4/16\n",
      "9585/9585 [==============================] - 10s 1ms/step - loss: 0.0165 - acc: 0.9985 - val_loss: 0.2006 - val_acc: 0.9609\n",
      "Epoch 5/16\n",
      "9585/9585 [==============================] - 9s 968us/step - loss: 0.0127 - acc: 0.9994 - val_loss: 0.1844 - val_acc: 0.9624\n",
      "Epoch 6/16\n",
      "9585/9585 [==============================] - 10s 1ms/step - loss: 0.0103 - acc: 0.9999 - val_loss: 0.1739 - val_acc: 0.9656\n",
      "Epoch 7/16\n",
      "9585/9585 [==============================] - 9s 959us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.1992 - val_acc: 0.9577\n",
      "Epoch 8/16\n",
      "9585/9585 [==============================] - 10s 1ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.1621 - val_acc: 0.9593\n",
      "Epoch 9/16\n",
      "9585/9585 [==============================] - 9s 964us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.1464 - val_acc: 0.9671\n",
      "Epoch 10/16\n",
      "9585/9585 [==============================] - 9s 919us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.1631 - val_acc: 0.9609\n",
      "Epoch 11/16\n",
      "9585/9585 [==============================] - 9s 936us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1659 - val_acc: 0.9593\n",
      "Epoch 12/16\n",
      "9585/9585 [==============================] - 9s 923us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.1453 - val_acc: 0.9671\n",
      "Epoch 13/16\n",
      "9585/9585 [==============================] - 9s 953us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1532 - val_acc: 0.9609\n",
      "Epoch 14/16\n",
      "9585/9585 [==============================] - 9s 940us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.1551 - val_acc: 0.9609\n",
      "Epoch 15/16\n",
      "9585/9585 [==============================] - 9s 938us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.1551 - val_acc: 0.9562\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "history = model.fit(np.concatenate([train_x, train_dev_x]), \n",
    "                    np.concatenate([train_y, train_dev_y]), \n",
    "                    validation_data=(dev_x, dev_y), \n",
    "                    callbacks=[earlystop], \n",
    "                    epochs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "[[  9.99981165e-01   8.53080292e-06   1.02381446e-05]\n",
      " [  2.26778375e-05   9.99959826e-01   1.75069181e-05]\n",
      " [  9.99796093e-01   9.90396220e-05   1.04884486e-04]\n",
      " ..., \n",
      " [  2.53954495e-04   3.26502282e-04   9.99419570e-01]\n",
      " [  9.98505950e-01   4.66120633e-04   1.02796080e-03]\n",
      " [  3.27962516e-05   4.45059995e-04   9.99522209e-01]]\n",
      "pred: [0 1 0 0 0 2 0 0 1 0 0 2 0 0 0 1 1 2 0 1 2 1 0 2 0 1 2 1 1 2 1 1 0 1 0 0 1\n",
      " 0 1 2 1 0 1 0 2 2 0 2 0 2 2 0 0 1 2 0 2 2 1 1 0 1 2 0 1 2 1 1 0 2 2 0 1 2\n",
      " 2 0 0 2 0 2 1 2 2 1 0 2 2 0 1 2 2 0 0 1 0 1 0 1 1 0]\n",
      "test: [0 1 0 0 0 2 0 0 1 0 0 2 0 0 0 1 1 2 0 1 0 1 0 2 0 1 2 1 1 2 1 1 0 1 0 0 1\n",
      " 0 1 2 1 0 1 0 2 2 0 2 0 2 2 0 0 1 2 0 2 2 1 1 0 1 2 0 1 2 1 1 0 2 2 0 2 2\n",
      " 2 0 0 2 0 2 1 2 2 2 0 2 2 0 1 2 2 0 0 1 0 1 0 1 1 0]\n",
      "639/639 [==============================] - 0s 466us/step\n",
      "Accuracy = 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate(model):\n",
    "    y_prob = model.predict_proba(test_x, verbose=0)\n",
    "    print(y_prob)\n",
    "    y_pred = model.predict(test_x)\n",
    "    print(f'pred: {np.argmax(y_pred[:100],axis=1)}')\n",
    "    y_true = np.argmax(test_y)\n",
    "    print(f'test: {np.argmax(test_y[:100],axis=1)}')\n",
    "\n",
    "    # evaluate the model\n",
    "    score, accuracy = model.evaluate(test_x, test_y)\n",
    "    print(\"Accuracy = {:.2f}\".format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# now evaluate the trained model against the unseen test data\n",
    "print(\"Evaluating model...\")\n",
    "acc = evaluate(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123360a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123375748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, label='Training acc')\n",
    "plt.plot(epochs, val_acc, label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_13 (Conv1D)           (None, 48, 128)           17024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 48, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 22, 64)            24640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 22, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 11, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 9, 24)             4632      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 9, 24)             96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 4, 24)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 124)               12028     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 375       \n",
      "=================================================================\n",
      "Total params: 59,563\n",
      "Trainable params: 59,131\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def mlp_model():        \n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_labels, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(lr=0.0000001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 9585 samples, validate on 639 samples\n",
      "Epoch 1/16\n",
      "9585/9585 [==============================] - 11s 1ms/step - loss: 0.5475 - acc: 0.8146 - val_loss: 0.3844 - val_acc: 0.8983\n",
      "Epoch 2/16\n",
      "9585/9585 [==============================] - 9s 922us/step - loss: 0.2124 - acc: 0.9581 - val_loss: 0.3303 - val_acc: 0.9139\n",
      "Epoch 3/16\n",
      "9585/9585 [==============================] - 9s 950us/step - loss: 0.1351 - acc: 0.9802 - val_loss: 0.2726 - val_acc: 0.9343\n",
      "Epoch 4/16\n",
      "9585/9585 [==============================] - 9s 976us/step - loss: 0.1028 - acc: 0.9862 - val_loss: 0.2630 - val_acc: 0.9374\n",
      "Epoch 5/16\n",
      "9585/9585 [==============================] - 9s 946us/step - loss: 0.0844 - acc: 0.9901 - val_loss: 0.2442 - val_acc: 0.9358\n",
      "Epoch 6/16\n",
      "9585/9585 [==============================] - 9s 959us/step - loss: 0.0630 - acc: 0.9947 - val_loss: 0.2634 - val_acc: 0.9358\n",
      "Epoch 7/16\n",
      "9585/9585 [==============================] - 9s 944us/step - loss: 0.0487 - acc: 0.9968 - val_loss: 0.2702 - val_acc: 0.9218\n",
      "Epoch 8/16\n",
      "9585/9585 [==============================] - 10s 1ms/step - loss: 0.0573 - acc: 0.9904 - val_loss: 0.2851 - val_acc: 0.9296\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "history = model.fit(np.concatenate([train_x, train_dev_x]), \n",
    "                    np.concatenate([train_y, train_dev_y]), \n",
    "                    validation_data=(dev_x, dev_y), \n",
    "                    callbacks=[earlystop], \n",
    "                    epochs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "[[  1.00000000e+00   5.63369273e-12   3.49122224e-11]\n",
      " [  3.71668676e-07   9.99999523e-01   8.21345054e-08]\n",
      " [  9.99999523e-01   8.59577725e-08   3.55601742e-07]\n",
      " ..., \n",
      " [  6.92226862e-08   2.53749821e-08   9.99999881e-01]\n",
      " [  9.99956846e-01   6.87520105e-06   3.62594037e-05]\n",
      " [  3.84246277e-06   9.42848772e-02   9.05711234e-01]]\n",
      "pred: [0 1 0 0 0 2 0 0 1 0 0 2 0 0 0 1 1 2 0 1 0 1 0 2 0 1 2 1 1 2 1 1 2 1 0 0 1\n",
      " 0 1 2 1 0 1 0 2 2 0 2 0 2 2 0 0 1 2 0 2 2 1 1 0 1 2 0 1 2 1 1 0 2 2 0 2 2\n",
      " 2 0 0 1 0 2 1 2 2 1 0 2 2 0 1 0 0 0 0 1 0 1 0 1 1 0]\n",
      "test: [0 1 0 0 0 2 0 0 1 0 0 2 0 0 0 1 1 2 0 1 0 1 0 2 0 1 2 1 1 2 1 1 0 1 0 0 1\n",
      " 0 1 2 1 0 1 0 2 2 0 2 0 2 2 0 0 1 2 0 2 2 1 1 0 1 2 0 1 2 1 1 0 2 2 0 2 2\n",
      " 2 0 0 2 0 2 1 2 2 2 0 2 2 0 1 2 2 0 0 1 0 1 0 1 1 0]\n",
      "639/639 [==============================] - 0s 433us/step\n",
      "Accuracy = 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate(model):\n",
    "    y_prob = model.predict_proba(test_x, verbose=0)\n",
    "    print(y_prob)\n",
    "    y_pred = model.predict(test_x)\n",
    "    print(f'pred: {np.argmax(y_pred[:100],axis=1)}')\n",
    "    y_true = np.argmax(test_y)\n",
    "    print(f'test: {np.argmax(test_y[:100],axis=1)}')\n",
    "\n",
    "    # evaluate the model\n",
    "    score, accuracy = model.evaluate(test_x, test_y)\n",
    "    print(\"Accuracy = {:.2f}\".format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# now evaluate the trained model against the unseen test data\n",
    "print(\"Evaluating model...\")\n",
    "acc = evaluate(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, label='Training acc')\n",
    "plt.plot(epochs, val_acc, label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_params = [0.1, 10, 25, 50, 100, 200, 500]\n",
    "accuracies = [0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(train_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-5ccdb93f881a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_param\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msvm_rbf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msvm_rbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_plus_dev_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_plus_dev_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_plus_dev_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_plus_dev_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_plus_dev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0my_test_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_rbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_plus_dev_x = np.concatenate([train_x, train_dev_x])\n",
    "train_plus_dev_y = np.concatenate([train_y, train_dev_y])\n",
    "\n",
    "for idx, C_param in enumerate(C_params):\n",
    "    svm_rbf = SVC(C=C_param, kernel='rbf', probability=True)\n",
    "    svm_rbf.fit(train_plus_dev_x.reshape(train_plus_dev_x.shape[0], train_plus_dev_x.shape[1]*train_plus_dev_x.shape[2]), np.argmax(train_plus_dev_y, axis=1))\n",
    "    y_test_predict = svm_rbf.predict(test_x.reshape(test_x.shape[0], test_x.shape[1]*test_x.shape[2]))\n",
    "    accuracies[idx] = accuracy_score(y_true=np.argmax(test_y,axis=1), y_pred=y_test_predict)\n",
    "    print(accuracies[idx])\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_params = [10, 25, 50, 100, 200, 500]\n",
    "accuracies = [0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796557120501\n",
      "0.881064162754\n",
      "0.892018779343\n",
      "0.904538341158\n",
      "0.921752738654\n",
      "0.926447574335\n",
      "[0.79655712050078242, 0.88106416275430355, 0.892018779342723, 0.90453834115805942, 0.92175273865414709, 0.92644757433489833]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_plus_dev_x = np.concatenate([train_x, train_dev_x])\n",
    "train_plus_dev_y = np.concatenate([train_y, train_dev_y])\n",
    "\n",
    "for idx, C_param in enumerate(C_params):\n",
    "    rf = RandomForestClassifier(n_estimators=C_param)\n",
    "    rf.fit(train_plus_dev_x.reshape(train_plus_dev_x.shape[0], train_plus_dev_x.shape[1]*train_plus_dev_x.shape[2]), np.argmax(train_plus_dev_y, axis=1))\n",
    "    y_test_predict = rf.predict(test_x.reshape(test_x.shape[0], test_x.shape[1]*test_x.shape[2]))\n",
    "    accuracies[idx] = accuracy_score(y_true=np.argmax(test_y,axis=1), y_pred=y_test_predict)\n",
    "    print(accuracies[idx])\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926447574335\n",
      "0.926447574335\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-645f99bc4b3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_param\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_plus_dev_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_plus_dev_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_plus_dev_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_plus_dev_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_plus_dev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0my_test_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 788\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "C_params = [10, 25, 50, 100, 200, 500]\n",
    "accuracies = [0, 0, 0, 0, 0, 0]\n",
    "for idx, C_param in enumerate(C_params):\n",
    "    gb = GradientBoostingClassifier(n_estimators=C_param)\n",
    "    gb.fit(train_plus_dev_x.reshape(train_plus_dev_x.shape[0], train_plus_dev_x.shape[1]*train_plus_dev_x.shape[2]), np.argmax(train_plus_dev_y, axis=1))\n",
    "    y_test_predict = rf.predict(test_x.reshape(test_x.shape[0], test_x.shape[1]*test_x.shape[2]))\n",
    "    accuracies[idx] = accuracy_score(y_true=np.argmax(test_y,axis=1), y_pred=y_test_predict)\n",
    "    print(accuracies[idx])\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
